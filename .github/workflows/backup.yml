name: Backup Database

on:
  schedule:
    # Daily full backup at 02:00 UTC
    - cron: '0 2 * * *'
    # NOTE: Reduced frequency to avoid excessive runs. To re-enable more
    # frequent backups, add another cron entry, e.g. hourly:
    # - cron: '0 * * * *'
  workflow_dispatch:
    inputs:
      kind:
        description: 'Backup kind (full|incremental|verify)'
        required: false
        default: 'full'

jobs:
  backup:
    runs-on: ubuntu-latest
    env:
      # Resolve BACKUP_KIND:
      #  - schedule 02:00 -> full
      #  - schedule */15 -> incremental
      #  - workflow_dispatch 'verify' -> full (fresh artifact for verification)
      #  - workflow_dispatch 'full'/'incremental' -> as requested
      # Simplified: GitHub does not expose which cron fired; choose input when dispatch, else 'full'.
      BACKUP_KIND: ${{ (github.event_name == 'workflow_dispatch' && inputs.kind) || 'full' }}
      BACKUP_OUT: backup_out
      DB_CONNECTION: ${{ secrets.DB_CONNECTION }}
      DB_TYPE: postgres
      BACKUP_BUCKET: ${{ secrets.BACKUP_BUCKET }}
      AWS_REGION: ${{ secrets.AWS_REGION }}
      AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
      AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      AZURE_CREDENTIALS: ${{ secrets.AZURE_CREDENTIALS }}
      AZURE_STORAGE_ACCOUNT: ${{ secrets.AZURE_STORAGE_ACCOUNT }}
      AZURE_STORAGE_CONTAINER: ${{ secrets.AZURE_STORAGE_CONTAINER }}
      HAS_DB: ${{ secrets.DB_CONNECTION != '' && 'true' || 'false' }}
      USE_EPHEMERAL: ${{ github.event_name == 'workflow_dispatch' && inputs.kind == 'verify' }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Install tools (psql, jq, awscli)
        run: |
          sudo apt-get update
          sudo apt-get install -y postgresql-client jq
          pipx install awscli || pip install --user awscli || true

      - name: Azure login (optional)
        if: env.AZURE_CREDENTIALS != ''
        uses: azure/login@v2
        with:
          creds: ${{ env.AZURE_CREDENTIALS }}

      - name: Ensure output dir
        run: mkdir -p "${BACKUP_OUT}"

      - name: Start ephemeral Postgres (verify mode)
        if: env.USE_EPHEMERAL == 'true'
        run: |
          docker run -d --name pg-verify -e POSTGRES_PASSWORD=postgres -p 5432:5432 postgres:16
          for i in {1..30}; do docker exec pg-verify pg_isready && break || sleep 2; done
          echo "DB_CONNECTION=postgres://postgres:postgres@127.0.0.1:5432/postgres" >> $GITHUB_ENV
          PGPASSWORD=postgres psql -h 127.0.0.1 -U postgres -d postgres -v ON_ERROR_STOP=1 <<'SQL'
          CREATE TABLE IF NOT EXISTS demo(id SERIAL PRIMARY KEY, note TEXT NOT NULL);
          INSERT INTO demo(note) VALUES ('seed row 1'),('seed row 2');
          SQL

      - name: Run backup script
        if: env.USE_EPHEMERAL == 'true' || env.HAS_DB == 'true'
        run: |
          chmod +x scripts/backup-db.sh
          ./scripts/backup-db.sh --type "${BACKUP_KIND}" --out "${BACKUP_OUT}"

      - name: Skip backup (no DB configured)
        if: env.USE_EPHEMERAL != 'true' && env.HAS_DB != 'true'
        run: |
          echo "DB_CONNECTION secret not set. Skipping backup run."

      - name: Upload as GitHub artifact (full - 30 days)
        if: env.BACKUP_KIND == 'full'
        uses: actions/upload-artifact@v4
        with:
          name: db-full-${{ github.run_id }}
          path: |
            ${{ env.BACKUP_OUT }}/*.gz
            ${{ env.BACKUP_OUT }}/*.sha256
            ${{ env.BACKUP_OUT }}/manifest-*.json
          retention-days: 30

      - name: Upload as GitHub artifact (incremental - 7 days)
        if: env.BACKUP_KIND != 'full'
        uses: actions/upload-artifact@v4
        with:
          name: db-incremental-${{ github.run_id }}
          path: |
            ${{ env.BACKUP_OUT }}/*.gz
            ${{ env.BACKUP_OUT }}/*.sha256
            ${{ env.BACKUP_OUT }}/manifest-*.json
          retention-days: 7

      - name: Upload to AWS S3 (optional)
        if: env.AWS_ACCESS_KEY_ID != '' && env.AWS_SECRET_ACCESS_KEY != '' && env.BACKUP_BUCKET != ''
        run: |
          set -e
          ts=$(date -u +%Y%m%d-%H%M%S)
          prefix="${BACKUP_KIND}/$ts"
          aws s3 cp ${BACKUP_OUT}/ s3://${BACKUP_BUCKET}/${prefix}/ --recursive --region "${AWS_REGION:-eu-west-1}"

      - name: Upload to Azure Blob (optional)
        if: env.AZURE_CREDENTIALS != '' && env.AZURE_STORAGE_ACCOUNT != '' && env.AZURE_STORAGE_CONTAINER != ''
        run: |
          set -e
          ts=$(date -u +%Y%m%d-%H%M%S)
          prefix="${BACKUP_KIND}/$ts"
          az storage blob upload-batch \
            --account-name "$AZURE_STORAGE_ACCOUNT" \
            --destination "$AZURE_STORAGE_CONTAINER/$prefix" \
            --source "$BACKUP_OUT" \
            --auth-mode login \
            --overwrite true

  verify-restore:
    if: ${{ github.event_name == 'workflow_dispatch' && inputs.kind == 'verify' }}
    needs: backup
    runs-on: ubuntu-latest
    env:
      BACKUP_OUT: backup_out
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Download artifact from current run
        uses: actions/download-artifact@v4
        with:
          name: db-full-${{ github.run_id }}
          path: ${{ env.BACKUP_OUT }}
        continue-on-error: true

      - name: Start PostgreSQL container for test restore
        run: |
          docker run -d --name pg-restore -e POSTGRES_PASSWORD=postgres -p 5432:5432 postgres:16
          # Wait for ready
          for i in {1..30}; do
            docker exec pg-restore pg_isready && break || sleep 2
          done

      - name: Install client tools
        run: sudo apt-get update && sudo apt-get install -y postgresql-client

      - name: Restore latest dump found
        run: |
          set -e
          file=$(ls -1 ${BACKUP_OUT}/db-*.dump.gz 2>/dev/null | tail -n1 || true)
          if [ -z "$file" ]; then
            echo "No dump found in artifact; skipping restore check."; exit 0
          fi
          gunzip -c "$file" > /tmp/restore.dump
          pg_restore -h 127.0.0.1 -U postgres -d postgres -v /tmp/restore.dump || true
          # Sanity query
          PGPASSWORD=postgres psql -h 127.0.0.1 -U postgres -d postgres -c "SELECT 1;"

      - name: Publish smoke result
        run: echo "Restore smoke test completed" 
